name: Data Pipeline

"on":
  workflow_dispatch:
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron: "30 23 * * *"

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: pip

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Setup credentials file
        env:
          OI_SFTP_USERNAME: ${{ secrets.OI_SFTP_USERNAME }}
          OI_SFTP_PASSWORD: ${{ secrets.OI_SFTP_PASSWORD }}
        run: |
          mkdir credentials
          echo ${{ secrets.FIREBASE_SERVICE_ACCOUNT_KEY }} | base64 -d > ./credentials/serviceAccountKey.json
          dvc remote modify --local oicloud user ${{ secrets.OI_SFTP_USERNAME }}
          dvc remote modify --local oicloud password ${{ secrets.OI_SFTP_PASSWORD }}

      - name: Run DVC pipelines
        env:
          PYTHONPATH: scripts
          GOOGLE_APPLICATION_CREDENTIALS: "./credentials/serviceAccountKey.json"
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        run: |
          # dvc pull
          dvc update -R working
          dvc repro -R scripts/reference_data
          dvc repro -R scripts/metrics

      - name: Process data for site
        env:
          PYTHONPATH: scripts

        run: |
          python scripts/process_for_site.py

      - name: Commit and Push changes
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: Data updates
          file_pattern: data docs
